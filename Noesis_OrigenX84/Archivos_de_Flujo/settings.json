{
  "llm": {
    "model": "llama3",
    "timeout": 60,
    "temperature": 0.7,
    "max_tokens": 800
  },
  "system": {
    "log_level": "INFO",
    "max_memory_entries": 1000,
    "auto_save": true
  }
}
